{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification ##\n",
    " - Implement by Piston Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 4, -1],\n",
       "       [ 2,  1],\n",
       "       [ 3, -1],\n",
       "       [ 1,  1],\n",
       "       [ 5, -1],\n",
       "       [ 6,  1],\n",
       "       [ 7,  1],\n",
       "       [ 8,  1],\n",
       "       [ 9, -1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.array([[0, 1], [4, -1], [2, 1], [3, -1], [1, 1],\n",
    "                  [5, -1], [6, 1], [7, 1], [8, 1], [9, -1]])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_first_step_weight(num_sample):\n",
    "#     初始化数据权值分布\n",
    "    return np.array([1/num_sample for i in range(num_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_sample(sample):\n",
    "#     对输入数据进行排序,方便算法计算\n",
    "# exp:IN:array([\n",
    "#        [ 0,  1],\n",
    "#        [ 4,  1],\n",
    "#        [ 2,  1],\n",
    "#        [ 3, -1],\n",
    "#        [ 1, -1]])\n",
    "#     OUT:array([\n",
    "#        [ 0,  1],\n",
    "#        [ 1, -1],\n",
    "#        [ 2,  1],\n",
    "#        [ 3, -1],\n",
    "#        [ 4,  1]])\n",
    "    return sample[sample[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找使误差率error最小的分类点 ###\n",
    "- 这个函数暂时仅以能实现为目的编写，不考虑任何优化\n",
    "- 此实现不能以0.5为阈值提前结束搜索，否则可能无法查找到最优error\n",
    "- 时间复杂度为O(2n)\n",
    "- 此函数为了快速实现对数据集敏感x必须为np.arange(0, N, 1), y~{1， -1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serch_minimize_error_point(D, sample):\n",
    "#     D[i]对应sample[i]的权重\n",
    "    sap_len = len(sample)\n",
    "\n",
    "\n",
    "#     先正向搜索：即 G(x): 1: x<v\n",
    "#                         -1: x>v\n",
    "#     实际上有n+1个分裂点\n",
    "    f_font_err = 0.\n",
    "    f_behind_error = np.sum(D[sample[:,1] != -1])\n",
    "    forward_err = f_font_err + f_behind_error\n",
    "    \n",
    "    f_split_point = 0.5  #最左边\n",
    "#     每遍历过一个元素根据其类别更新f_font_err和f_behind_err如果error变小了则更新forward_err\n",
    "    for i in range(sap_len):\n",
    "        split_point = i + 0.5\n",
    "#         如果当前y值==1：则f_font_err不变，f_behind_error减小\n",
    "        if sample[i][1] == 1:\n",
    "            f_behind_error -= D[i]\n",
    "            if f_font_err + f_behind_error < forward_err:\n",
    "#                 如果当前error最小则更新forward_err和最优分裂点\n",
    "                forward_err = f_font_err + f_behind_error\n",
    "                f_split_point = split_point\n",
    "\n",
    "#         如果当前y值==-1：则f_font_err增大，f_behind_error不变\n",
    "        else:\n",
    "            f_font_err += D[i]\n",
    "#             不能提前退出，会出现问题，跟我的实现方式有关\n",
    "#             if f_font_err + f_behind_error > 0.5:\n",
    "#                 break\n",
    "\n",
    "\n",
    "\n",
    "#     反向搜索：即 G(x):  1: x>v\n",
    "#                        -1: x<v\n",
    "#     不会改变for循环的方向\n",
    "    b_font_err = 0.\n",
    "    b_behind_err = np.sum(D[sample[:,1] != 1])\n",
    "    backward_err = b_font_err + b_behind_err\n",
    "    b_split_point = 0.5\n",
    "\n",
    "    for i in range(sap_len):\n",
    "        split_point = i + 0.5\n",
    "        \n",
    "        if sample[i][1] == 1:\n",
    "            b_font_err += D[i]\n",
    "#             if b_font_err + b_behind_err > 0.5:\n",
    "#                 break\n",
    "        else:\n",
    "            b_behind_err -= D[i]\n",
    "            if b_font_err + b_behind_err < backward_err:\n",
    "                backward_err = b_font_err + b_behind_err\n",
    "                b_split_point = split_point\n",
    "\n",
    "#     判断哪种方式得到的error最小并确定搜索方式\n",
    "\n",
    "    if forward_err <= backward_err:\n",
    "        min_error = forward_err\n",
    "        final_point = f_split_point\n",
    "        serch_type = 'forward'\n",
    "    else:\n",
    "        min_error = backward_err\n",
    "        final_point = b_split_point\n",
    "        serch_type = 'backward'\n",
    "    Gm = {'sp': final_point, 'type': serch_type}\n",
    "    return min_error, Gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据error计算当前分类器权重alpha ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alpha m\n",
    "def compute_alpha(error):\n",
    "    return 1/2 * np.log((1-error)/error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新训练数据的权值分布D ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gm即G(x)为一个dict{'sp' : split_point, 'type': serch_type}\n",
    "def update_weight(sample, Dm, alpha, Gm):\n",
    "    N = len(sample)\n",
    "    split_point = Gm['sp']\n",
    "    serch_type = Gm['type']\n",
    "\n",
    "    if serch_type == 'forward':\n",
    "\n",
    "        Gm_ems = np.array([1. if i < split_point else -1. for i in range(N)])\n",
    "    else:\n",
    "\n",
    "        Gm_ems = np.array([-1. if i < split_point else 1. for i in range(N)])\n",
    "\n",
    "    yi = sample[:, 1]\n",
    "\n",
    "    Zm = np.sum(Dm * np.exp(-alpha * yi * Gm_ems))\n",
    "\n",
    "    D_update = Dm / Zm * np.exp(-alpha * yi * Gm_ems)\n",
    "    \n",
    "    return D_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据当前已训练好的分类器，在训练集上统计预测错的数据总数 ###\n",
    "- 此函数会帮助判断算法是否已经可以结束\n",
    "- 并且可以记录每轮算法分类错的点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fx为一个list，list中的元素为dict，dict中保存每一个fi(x)的alpha和G(x)\n",
    "def get_misclassification_point(sample, fx):\n",
    "#     计算误分类点，fx为组合分类器，要先计算组合分类器给出的0/1概率总和，然后根据最大值决定分类器输出\n",
    "#     再比较true_label判断是否为误分类点\n",
    "    num_Gm = len(fx)\n",
    "    len_smp = len(sample)\n",
    "    misclassification_point = []\n",
    "#     获取组合分类器对y_hat_n的结果\n",
    "    for n in range(len_smp):\n",
    "#         统计组合分类器对正负样本的概率\n",
    "        pos_prop = 0.\n",
    "        neg_prop = 0.\n",
    "        for m in range(num_Gm):\n",
    "            Gm = fx[m]['Gm']\n",
    "            alpha = fx[m]['alpha']\n",
    "            Gm_p = Gm['sp']\n",
    "            Gm_type = Gm['type']\n",
    "            \n",
    "            if Gm_type == 'forward':\n",
    "                if n < Gm_p:  #正样本\n",
    "                    pos_prop += alpha\n",
    "                else:  #负样本\n",
    "                    neg_prop += alpha\n",
    "            else:\n",
    "                if n < Gm_p:  #负样本\n",
    "                    neg_prop += alpha\n",
    "                else:  #正样本\n",
    "                    pos_prop += alpha\n",
    "        if pos_prop > neg_prop:\n",
    "            y_hat_n = 1\n",
    "        else:\n",
    "            y_hat_n = -1\n",
    "        y_n = sample[n][1]\n",
    "        \n",
    "        if y_n != y_hat_n:\n",
    "#             print(\"true lab: %d, Pred_lab: %d.\" % (y_n, y_hat_n))\n",
    "            misclassification_point.append(n)\n",
    "    return misclassification_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法真正迭代 ###\n",
    "- 测试数据来自《统计学习方法》——李航 P140-P142\n",
    "- 无差别复现例题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_N定义最大迭代次数\n",
    "def AdaBoost(max_N, sample):\n",
    "    sample = sort_sample(sample)\n",
    "    len_sap = len(sample)\n",
    "    \n",
    "    cache_D = []   #迭代过程中数据权值分布\n",
    "    cache_misclassification_point = []  #每次迭代组合分类器分类错误的点\n",
    "    cache_min_error = []   #每次迭代的min_error——很重要，一般就这个函数出错\n",
    "    fx = []    #组合分类器\n",
    "    num_iter = 0   #迭代次数\n",
    "    \n",
    "    D = None  #每轮迭代的权值分布，提前定义，以免循环中途被释放\n",
    "    for m in range(1, max_N+1):\n",
    "        if m == 1:  #如果是第一次迭代初始化权值分布\n",
    "            D = init_first_step_weight(len_sap)\n",
    "            cache_D.append(D)\n",
    "#         使用具有权值分布Dm的训练数据集学习，得到基本分类器Gm,同时计算Gm在训练数据集上的分类误差率（其实是根据最小的误差率决定Gm）\n",
    "        min_error, Gm = serch_minimize_error_point(D, sample)\n",
    "        cache_min_error.append(min_error)\n",
    "#         计算Gm的系数\n",
    "        alpha = compute_alpha(min_error)\n",
    "#         更新训练数据集的权值分布\n",
    "        D = update_weight(sample, D, alpha, Gm)\n",
    "        cache_D.append(D)\n",
    "#         构建基本分类器\n",
    "        fxi = {'alpha': alpha, 'Gm':Gm}\n",
    "#         组合基本分类器\n",
    "        fx.append(fxi)\n",
    "#         判断组合分类器是否能完全正确分类样本/训练集\n",
    "        misclassification_point = get_misclassification_point(sample, fx)\n",
    "        cache_misclassification_point.append(misclassification_point)\n",
    "#         如果组合分类器可以完全正确分类样本，则提前结束迭代\n",
    "        if len(misclassification_point) == 0:\n",
    "            num_iter = m\n",
    "            break\n",
    "        if m == max_N:\n",
    "            num_iter = m\n",
    "#     返回所有迭代过程中的数据，可以帮助排查算法错误，按需获取\n",
    "    return cache_D, cache_misclassification_point, cache_min_error, fx, num_iter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_D, cache_misclassification_point, cache_min_error, fx_final, num_iter = AdaBoost(10, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]),\n",
       " array([ 0.07142857,  0.07142857,  0.07142857,  0.07142857,  0.07142857,\n",
       "         0.07142857,  0.16666667,  0.16666667,  0.16666667,  0.07142857]),\n",
       " array([ 0.04545455,  0.04545455,  0.04545455,  0.16666667,  0.16666667,\n",
       "         0.16666667,  0.10606061,  0.10606061,  0.10606061,  0.04545455]),\n",
       " array([ 0.125     ,  0.125     ,  0.125     ,  0.10185185,  0.10185185,\n",
       "         0.10185185,  0.06481481,  0.06481481,  0.06481481,  0.125     ])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 8], [3, 4, 5], []]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_misclassification_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30000000000000004, 0.21428571428571438, 0.18181818181818196]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_min_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Gm': {'sp': 2.5, 'type': 'forward'}, 'alpha': 0.42364893019360172},\n",
       " {'Gm': {'sp': 8.5, 'type': 'forward'}, 'alpha': 0.64964149206513011},\n",
       " {'Gm': {'sp': 5.5, 'type': 'backward'}, 'alpha': 0.75203869838813653}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
